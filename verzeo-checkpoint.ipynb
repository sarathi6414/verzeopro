{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358ee878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\parathasarathi\n",
      "[nltk_data]     s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\parathasarathi\n",
      "[nltk_data]     s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\parathasarathi s\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\parathasarathi s\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\parathasarathi s\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the best accuracy is Multinomial Naïve Bayes with an accuracy of 91.90%.\n",
      "\n",
      "Classification Report for Multinomial Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        58\n",
      "           1       0.93      0.98      0.96       572\n",
      "\n",
      "    accuracy                           0.92       630\n",
      "   macro avg       0.79      0.63      0.67       630\n",
      "weighted avg       0.90      0.92      0.90       630\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 16  42]\n",
      " [  9 563]]\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.07        58\n",
      "           1       0.91      1.00      0.95       572\n",
      "\n",
      "    accuracy                           0.91       630\n",
      "   macro avg       0.96      0.52      0.51       630\n",
      "weighted avg       0.92      0.91      0.87       630\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[  2  56]\n",
      " [  0 572]]\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.91      1.00      0.95       572\n",
      "\n",
      "    accuracy                           0.91       630\n",
      "   macro avg       0.45      0.50      0.48       630\n",
      "weighted avg       0.82      0.91      0.86       630\n",
      "\n",
      "Confusion Matrix for KNN:\n",
      "[[  0  58]\n",
      " [  0 572]]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 1: Read the dataset\n",
    "file_path = r\"C:\\Users\\parathasarathi s\\Downloads\\amazon_alexa_data (2).csv\"  # Ensure the path is correct\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Remove null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Step 3: Preprocess the Amazon Alexa reviews\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['clean_reviews'] = df['verified_reviews'].apply(preprocess_text)\n",
    "\n",
    "# Step 4: Transform the words into vectors\n",
    "# Using Count Vectorizer\n",
    "cv = CountVectorizer()\n",
    "X_cv = cv.fit_transform(df['clean_reviews'])\n",
    "\n",
    "# Using TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(df['clean_reviews'])\n",
    "\n",
    "# Step 5: Split data into training and test data\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_cv, df['feedback'], test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, df['feedback'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Apply models and generate predictions\n",
    "# a) Multinomial Naïve Bayes Classification\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_cv, y_train_cv)\n",
    "nb_pred = nb_model.predict(X_test_cv)\n",
    "\n",
    "# b) Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "lr_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# c) KNN Classification\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "knn_pred = knn_model.predict(X_test_tfidf)\n",
    "\n",
    "# Step 7: Predict the feedback for test data\n",
    "# Predictions are stored in nb_pred, lr_pred, knn_pred\n",
    "\n",
    "# Step 8: Compute Confusion matrix and classification report\n",
    "# for each of these models\n",
    "conf_matrix_nb = confusion_matrix(y_test_cv, nb_pred)\n",
    "class_report_nb = classification_report(y_test_cv, nb_pred)\n",
    "\n",
    "conf_matrix_lr = confusion_matrix(y_test_tfidf, lr_pred)\n",
    "class_report_lr = classification_report(y_test_tfidf, lr_pred)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test_tfidf, knn_pred)\n",
    "class_report_knn = classification_report(y_test_tfidf, knn_pred)\n",
    "\n",
    "# Step 9: Report the model with the best accuracy\n",
    "# This can be done by comparing the accuracy scores\n",
    "accuracy_nb = nb_model.score(X_test_cv, y_test_cv)\n",
    "accuracy_lr = lr_model.score(X_test_tfidf, y_test_tfidf)\n",
    "accuracy_knn = knn_model.score(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "best_model = max([(accuracy_nb, 'Multinomial Naïve Bayes'), (accuracy_lr, 'Logistic Regression'), (accuracy_knn, 'KNN')],\n",
    "                 key=lambda x: x[0])\n",
    "\n",
    "print(f\"The model with the best accuracy is {best_model[1]} with an accuracy of {best_model[0]*100:.2f}%.\")\n",
    "\n",
    "# Print classification reports and confusion matrices\n",
    "print(\"\\nClassification Report for Multinomial Naive Bayes:\")\n",
    "print(class_report_nb)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(conf_matrix_nb)\n",
    "\n",
    "print(\"\\nClassification Report for Logistic Regression:\")\n",
    "print(class_report_lr)\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(conf_matrix_lr)\n",
    "\n",
    "print(\"\\nClassification Report for KNN:\")\n",
    "print(class_report_knn)\n",
    "print(\"Confusion Matrix for KNN:\")\n",
    "print(conf_matrix_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383152cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea12d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eaad37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
